<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ayano Hiranaka</title>

    <meta name="author" content="Ayano Hiranaka">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Top Block -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ayano Hiranaka
                </p>
                <p>
                  I am an incoming CS PhD student at University of Southern California (USC) co-advised by Professor
                  <a href="">Daniel Seita</a>
                  and Professor 
                  <a href="">Erdem Biyik</a>.
                </p>
                <p>
                  Currently, I am working as a research intern at Sony AI, Tokyo.
                </p>
                <p>
                  Prior to coming to USC, I completed my Master's degree at Stanford University, where I was a research assistant at
                  <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a>
                  working with
                  <a href="https://profiles.stanford.edu/fei-fei-li">Prof. Fei-Fei Li</a>
                  ,
                  <a href="https://jiajunwu.com/">Prof. Jiajun Wu</a>,
                  and 
                  <a href="https://ai.stanford.edu/~zharu/">Dr. Ruohan Zhang.</a>
                  I received my undergraduate degree in mechanical engineering from the University of Illinois at Urbana-Champaign (UIUC).
                </p>
                <p>
                  My experiences are a unique blend of computer science and mechanical engineering,
                  ranging from AI to robotics to mechanical design.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ayanoh@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="documents/ayano_hiranaka_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=KWZsjx8AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/misoshiruseijin">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/headshots/headshot_2024.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/headshots/headshot_2024.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Publications Block -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  I am passionate about designing robots that can be incorporated into everyday life as human companions.
                  My research interest lies in developing methods that enable robots to 
                  <u><b>communicate effectively and collaborate seamlessly with humans</b></u>
                  in households or public spaces, 
                  <u><b>increasing the quality of human lives</b></u>
                  , while 
                  <u><b>evolving alongside humans by learning from them.</b></u>
                  Topics of interest include human-in-the-loop learning, interactive human-robot collaboration, reinforcement learning, and imitation learning,
                  especially for robotics applications.
                </p>
              </td>
            </tr>
          </tbody></table>
    
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
                <!-- Research Works -->
                <!-- HERO -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <img src='images/HERO_thumbnail.gif' width="160">
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a>
                      <span class="papertitle">Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning</span>
                    </a>
                    <br>
                    <strong><u>Ayano Hiranaka*</u></strong>, Shang-Fu Chen*, Chieh-Hsin Lai*, 
                    Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, 
                    Shao-Hua Sun**, Yuki Mitsufuji**
                    <br>
                    <em>ICLR</em> 2025 &nbsp
                    <br>
                    <!-- <a href="https://noir-corl.github.io/">project page</a> -->
                    <!-- / -->
                    <a href="https://arxiv.org/pdf/2410.05116">paper</a>
                    <p></p>
                    <p>
                    Finetuning text-to-image diffusion models for a variety of tasks in a human-feedback-efficient manner 
                    by combining feedback-aligned representation learning and feedback-guided image generation.
                    </p>
                  </td>
                  </tr>
                <!-- NOIR -->
                <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/noir_thumbnail.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://noir-corl.github.io/">
                    <span class="papertitle">NOIR: Neural Signal Operated Intelligent Robot for Daily Activities</span>
                  </a>
                  <br>
                  Ruohan Zhang*, Sharon Lee*, Minjune Hwang*,
                  <strong><u>Ayano Hiranaka*</u></strong>,
                  Chen Wang, Wensi Ai, Jin Jie Ryan Tan, Shreya Gupta,
                  Yilun Hao, Gabrael Levine, Ruohan Gao, Anthony Norcia,
                  Li Fei-Fei, Jiajun Wu
                  <br>
                  <em>CoRL</em> 2023 &nbsp
                  <br>
                  <a href="https://noir-corl.github.io/">project page</a>
                  /
                  <a href="https://openreview.net/pdf?id=eyykI3UIHa">paper</a>
                  <p></p>
                  <p>
                  Brain-robot interface system for everyday activities using EEG signal decoding,
                  primitive skills, and robot intelligence aided by foundation models. 
                  </p>
                </td>
                </tr>
                <!-- SEED -->
                <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/SEED_thumbnail.gif' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://seediros23.github.io/">
                    <span class="papertitle">Primitive Skill-based Robot Learning from Human Evaluative Feedback</span>
                  </a>
                  <br>
                  <strong><u>Ayano Hiranaka*</u></strong>,
                  Minjune Hwang*, Sharon Lee, Chen Wang, Li Fei-Fei, Jiajun Wu, Ruohan Zhang
                  <br>
                  <em>(*equal contribution, alphabetically ordered)</em>
                  <br>
                  <em>IROS</em> 2023 &nbsp
                  <br>
                  <a href="https://seediros23.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2307.15801">paper</a>
                  <p></p>
                  <p>
                  Combining intuitive skill-based action space and human evaluative feedback, enabling a
                  more safe and sample efficient long-horizon task learning in the real world.
                  </p>
                </td>
                </tr>
                <!-- DREF -->
                <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/dref_thumbnail.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://sites.google.com/view/dr-hrl">
                    <span class="papertitle">A Dual Representation Framework for Robot Learning with Human Guidance</span>
                  </a>
                  <br>
                  <!-- <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang*</a>,
                  <a href="https://dhruvabansal.com/">Dhruva Bansal*</a>,
                  <a>Yilun Hao*</a>,
                  <strong>Ayano Hiranaka</strong>,
                  <a href="https://robertomartinmartin.com/">Roberto Mart√≠n-Mart√≠n</a>,
                  <a href="https://www.chenwangjeremy.net/">Chen Wang</a>,
                  <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
                  <a href="https://jiajunwu.com/">Jiajun Wu</a>, -->
                  Ruohan Zhang*, Dhruva Bansal*, Yilun Hao*,
                  <strong><u>Ayano Hiranaka</u></strong>,
                  Roberto Mart√≠n-Mart√≠n, Chen Wang, Li Fei-Fei, Jiajun Wu,
                  <br>
                  <em><font color="red">Best paper award at Aligning Robot Representations with Humans workshop</font></em>
                  <br>
                  <em>CoRL</em> 2022 &nbsp
                  <br>
                  <a href="https://sites.google.com/view/dr-hrl">project page</a>
                  /
                  <a href="https://openreview.net/pdf?id=H6rr_CGzV9y">paper</a>
                  <p></p>
                  <p>
                  A sample-efficient RLHF framework for low-level robot control policy leveraging 
                  a human-interpretable high-level state representation for active query.
                  </p>
                </td>
                </tr>

              </tr>           

          <!-- Projects Block -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Research Projects</h2>
            </td>
            </tr>
          </tbody></table>
            
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
            <!-- Projects -->
            <!-- Transient Object Spectrometer -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/object_spectrometer.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="videos/object_spectrometer.mp4">
                  <span class="papertitle">Senior Capstone Project: Transient Object Spectrometer</span>
                </a>
                <br>
                <em>University of Illinois at Urbana-Champaign</em>, 2019 &nbsp
                <br>
                <a href="documents/object_spectrometer_report.pdf">project report</a>
                /
                <a href="videos/object_spectrometer.mp4">video</a>
                <p></p>
                <p>
                Mechatronic system that detect, track, and collect spectral data from moving, light-emitting
                objects in the night sky.<br>
                <i>Mentored and sponsored by Prof. Nick Glumac.</i>
                </p>
              </td>
            </tr>
            <!-- Music Transcription -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/music_transcription_thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="documents/music_transcription_report.pdf">
                  <span class="papertitle">Identification of Musical Note Played on Piano via Feedback Particle Filter</span>
                </a>
                <br>
                <em>University of Illinois at Urbana-Champaign</em>, 2019 &nbsp
                <br>
                <a href="documents/music_transcription_report.pdf">project report</a>
                <p></p>
                <p>
                Real-time identification of a note played on a piano with a probabilistic approach using
                a feedback particle filtering algorithm.<br>
                <i>Mentored by Prof. Amirhossein Taghvaei and Prof. Prashant Mehta.</i>
                </p>
              </td>
            </tr>
            <!-- ACF Drilling -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/acf_thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="documents/acf_drilling_report.pdf">
                  <span class="papertitle">Investigating the Effects of ACF Spray Angle and Distance on its Performance for Micro-Drilling</span>
                </a>
                <br>
                <em>University of Illinois at Urbana-Champaign</em>, 2019 &nbsp
                <br>
                <a href="documents/acf_drilling_report.pdf">project report</a>
                <p></p>
                <p>
                Investigation of atomization-based cutting fluid spray condition to maximize tool life 
                for deep micro-drilling. Automatic drill parameter measurements from microscope images
                using keypoint detection.<br>
                <i>Mentored by Dr. Amy Lee and Prof. Shiv Kapoor.</i>
                </p>
              </td>
            </tr>

          <!-- Misc Projects Block -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Miscllaneous Projects</h2>
            </td>
            </tr>
          </tbody></table>
            
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>   
            <!-- Projects -->
            <!-- SimRPG -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/simrpg_thumbnail.gif' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="videos/simrpg.mp4">
                  <span class="papertitle">Retro-Style Simulation RPG in Unity</span>
                </a>
                <br>
                <a href="documents/simrpg.pdf">current progress</a>
                /
                <a href="videos/simrpg.mp4">video</a>
                <p></p>
                <p>
                In progress retro-style simulaiton RPG in Unity.<br>
                <i>Personal hobby project.</i>
                </p>
              </td>
            </tr>
            <!-- AR Piano -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/ar_piano_thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="documents/ar_piano.pdf">
                  <span class="papertitle">AR Piano Playing Using Real-Time Hand Tracking</span>
                </a>
                <br>
                <em>Stanford University</em>, 2022 &nbsp
                <br>
                <a href="documents/ar_piano.pdf">project report</a>
                <p></p>
                <p>
                AR piano using real-time hand keypoint tracking from RGB webcam stream.<br>
                <i>CS231A Computer Vision from 3D Reconstruction to Recognition course project.</i>
                </p>
              </td>
            </tr>
            <!-- Conundrum -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/conundrum_thumbnail.gif' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="documents/conundrum_report.pdf">
                  <span class="papertitle">Conun-Drum Bot: A Drum-Playing Humanoid Simulator</span>
                </a>
                <br>
                <em>Stanford University</em>, 2022 &nbsp
                <br>
                <a href="documents/conundrum_report.pdf">project report</a>
                /
                <a href="videos/conundrum.mp4">video</a>
                <p></p>
                <p>
                Drum-player humanoid simulator that playes the beats speficied by a user.<br>
                <i>CS225A Experimental Robotics course project.</i>
                </p>
              </td>
            </tr> 
            <!-- Blender -->
            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/blender_cg_thumbnail.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="images/blender_cg_highres.png">
                  <span class="papertitle">Blender CG Project</span>
                </a>
                <br>
                <em>Stanford University</em>, 2022 &nbsp
                <br>
                <a href="images/blender_cg_highres.png">high-resolution image</a>
                <p></p>
                <p>
                Blender CG artwork created from scratch in introductory computer graphics course.<br>
                <i>CS148 Intro to Computer Graphics course project.</i>
                </p>
              </td>
            </tr>  -->
            <!-- Mechanical Design Projects -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/mechanical_design_thumbnail.gif' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="documents/.pdf"> -->
                  <span class="papertitle">Mechanical Design Projects</span>
                <!-- </a> -->
                <br>
                <em>University of Illinois at Urbana-Champaign</em>, 2018-2019 &nbsp
                <br>
                <!-- <a href="videos/.mp4">Mechanical Slicer</a>
                /
                <a href="videos/.mp4">Quadruped Walker</a>
                /
                <a href="videos/.mp4">Steel Ball Transporter</a>
                <p></p> -->
                <p>
                A vegetable slicer operating from single crank input,
                quadruped walking robot, and steel ball transporter mechanism.<br>
                <!-- <i>Course projects.</i> -->
                </p>
              </td>
            </tr> 

  </tbody></table>

    </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template borrowed from <a href="https://jonbarron.info/">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
